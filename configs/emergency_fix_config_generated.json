{
  "comment": "Improved configuration addressing all 13 identified issues",
  "teacher_model": "huihui-ai/Huihui-MoE-1B-A0.6B",
  "student_model": "HuggingFaceTB/SmolLM-135M",
  "num_experts": 8,
  "top_k": 2,
  "batch_size": 4,
  "gradient_accumulation_steps": 8,
  "learning_rate": 3e-05,
  "router_lr": 0.0001,
  "num_epochs": 3,
  "warmup_steps": 468,
  "eval_steps": 2000,
  "save_epochs": 1,
  "max_length": 384,
  "alpha_kd": 0.3,
  "alpha_feature": 0.1,
  "alpha_attention": 0.1,
  "alpha_layerwise": 0.05,
  "alpha_contrastive": 0.05,
  "temperature": 2.0,
  "min_temperature": 1.5,
  "use_temperature_curriculum": true,
  "contrastive_temp": 0.07,
  "label_smoothing": 0.1,
  "use_curriculum": true,
  "initial_top_k": 1,
  "final_top_k": 4,
  "load_balance_weight": 0.01,
  "noise_std": 0.1,
  "weight_decay": 0.01,
  "max_grad_norm": 1.0,
  "scheduler_type": "cosine",
  "use_amp": true,
  "amp_dtype": "bfloat16",
  "loss_chunk_size": 128,
  "attention_layers": 1,
  "use_adaptive_loss_balancing": true,
  "adaptive_balance_strength": 1.0,
  "adaptive_balance_min_multiplier": 0.15,
  "adaptive_balance_max_multiplier": 2.0,
  "adaptive_balance_epsilon": 0.0001,
  "adaptive_reference_loss": "lm",
  "kd_top_k": 256,
  "use_gradient_checkpointing": true,
  "dataset_subset_size": 50000,
  "num_workers": 1,
  "use_dynamic_batching": true,
  "checkpoint_dir": "./checkpoints",
  "log_dir": "./logs",
  "cache_dir": "./cache",
  "memory_threshold": 0.85,
  "use_early_stopping": true,
  "early_stopping_patience": 10,
  "early_stopping_min_delta": 0.001,
  "use_ema": true,
  "ema_decay": 0.9999,
  "use_wandb": false,
  "project_name": "student-aware-distillation",
  "log_component_losses": true,
  "log_gradient_norms": true,
  "_fixed_by": "diagnose_and_fix.py",
  "_original_config": "configs/improved_config.json"
}