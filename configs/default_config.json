{
  "teacher_model": "huihui-ai/Huihui-MoE-1B-A0.6B",
  "student_model": "HuggingFaceTB/SmolLM-135M",
  "num_experts": 8,
  "top_k": 2,
  
  "batch_size": 4,
  "gradient_accumulation_steps": 8,
  "learning_rate": 5e-5,
  "router_lr": 1e-4,
  "num_epochs": 3,
  "warmup_steps": 500,
  "eval_steps": 500,
  "save_epochs": 1,
  "max_length": 512,
  
  "alpha_kd": 0.7,
  "alpha_feature": 0.1,
  "alpha_attention": 0.1,
  "alpha_layerwise": 0.05,
  "alpha_contrastive": 0.05,
  
  "temperature": 2.0,
  "min_temperature": 1.5,
  "contrastive_temp": 0.07,
  
  "initial_top_k": 1,
  "final_top_k": 4,
  "load_balance_weight": 0.01,
  "noise_std": 0.1,
  
  "weight_decay": 0.01,
  "max_grad_norm": 1.0,
  "scheduler_type": "cosine",
  "use_amp": true,
  "amp_dtype": "bfloat16",
  "loss_chunk_size": 128,
  "attention_layers": 4,
  "use_adaptive_loss_balancing": true,
  "adaptive_balance_strength": 0.5,
  "adaptive_balance_min_multiplier": 0.25,
  "adaptive_balance_max_multiplier": 2.0,
  
  "dataset_subset_size": 50000,
  "num_workers": 2,
  "use_dynamic_batching": true,
  
  "checkpoint_dir": "./checkpoints",
  "log_dir": "./logs",
  "cache_dir": "./cache",
  
  "memory_threshold": 0.85,
  
  "use_wandb": false,
  "project_name": "student-aware-distillation",
  
  "use_ema": true,
  "ema_decay": 0.9999,
  "use_curriculum": true,
  "label_smoothing": 0.1,
  "kd_top_k": 0,
  
  "use_early_stopping": true,
  "early_stopping_patience": 3,
  "early_stopping_min_delta": 0.01
}